{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm # loops show smart progress meter\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class Player(Enum):\n",
    "#    NOUGHTS = -1\n",
    "#    CROSSES = 1\n",
    "\n",
    "class Board:\n",
    "    \"\"\" holds a 3x3 board.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, bInit):\n",
    "        \"\"\" bInit is a numpy array.\n",
    "        \"\"\"\n",
    "        \n",
    "        assert(bInit.shape == ((3,3)))\n",
    "        \n",
    "        self.b = bInit\n",
    "    \n",
    "    def isGameOver(self):\n",
    "        return np.any(self.b == 0) == False\n",
    "    \n",
    "    def isEmptyCell(self, x, y):\n",
    "        return self.b[x, y] == 0\n",
    "    \n",
    "    def check(self, player):\n",
    "        \"\"\"\n",
    "        This function returns player if this player won, 2 if draw, and 0 otherwise.\n",
    "        \"\"\"\n",
    "        \n",
    "        assert(player == 1 or player == -1)\n",
    "        \n",
    "        # check horizontal and vertical lines for win.\n",
    "        \n",
    "        for i in range(3):\n",
    "            if (self.b[i,0] == player and self.b[i,0] == self.b[i,1] == self.b[i,2]) or \\\n",
    "               (self.b[0,i] == player and self.b[0,i] == self.b[1,i] == self.b[2,i]):\n",
    "                return player\n",
    "\n",
    "        # check diagonals for win.\n",
    "        \n",
    "        if (self.b[0,0] == player and self.b[0,0] == self.b[1,1] == self.b[2,2]) or \\\n",
    "           (self.b[0,2] == player and self.b[0,2] == self.b[1,1] == self.b[2,0]):\n",
    "            return player\n",
    "        \n",
    "        \n",
    "        if self.isGameOver():   # draw.\n",
    "            return 2\n",
    "        \n",
    "        return 0    # game not over.\n",
    "\n",
    "    def toKey(self):\n",
    "        \n",
    "        s = 0\n",
    "        i = 0\n",
    "        \n",
    "        for x in range(3):\n",
    "            for y in range(3):\n",
    "                s += (self.b[x,y] + 2) * 10**i\n",
    "                i += 1\n",
    "\n",
    "        return int(s)\n",
    "\n",
    "    def fromKey(self, i):\n",
    "        \n",
    "        self.b = np.zeros((3, 3))\n",
    "        \n",
    "        for x in range(3):\n",
    "            for y in range(3):\n",
    "                self.b[x,y] = i%10 - 2\n",
    "                i = int(i/10)\n",
    "                \n",
    "    def move(self, x, y, player):\n",
    "        self.b[x,y] = player\n",
    "        \n",
    "        return self.check(player)\n",
    "    \n",
    "    def possibleActions(self):\n",
    "        \n",
    "        \"\"\" returns list of empty cells using linear coords.\n",
    "        \"\"\"\n",
    "        \n",
    "        actions = []\n",
    "        \n",
    "        for x in range(3):\n",
    "            for y in range(3):\n",
    "                if self.isEmptyCell(x, y):\n",
    "                    actions.append(x + 3 * y)\n",
    "        \n",
    "        return actions\n",
    "    \n",
    "def getAllStartStates():\n",
    "    def f(keys, b, i):\n",
    "        # i is initial cell in linear coords.\n",
    "        \n",
    "        assert(i >= 0 and i < 9)\n",
    "        \n",
    "        x = i % 3\n",
    "        y = int(i / 3)\n",
    "        \n",
    "        for p in [-1, 0, 1]:\n",
    "            b.b[x,y] = p\n",
    "            \n",
    "            if np.sum(b.b == 1) - np.sum(b.b == -1) in [0, 1] and b.check(1) == 0 and b.check(-1) == 0:\n",
    "                keys.append(b.toKey())\n",
    "            \n",
    "            if i < 8:\n",
    "                f(keys, b, i+1)\n",
    "    \n",
    "    board = Board(np.zeros((3,3)))\n",
    "    boardKeys = [board.toKey()]\n",
    "    \n",
    "    f(boardKeys, board, 0)\n",
    "    \n",
    "    return boardKeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policyRandomMove(board, pure = False):\n",
    "    \n",
    "    p = np.where(board.b == 0, 1, 0) # p is 3x3 grid which is 1 where we have empty cells\n",
    "    \n",
    "    if not pure:\n",
    "        if p[1,1] == 1:  # (1, 1) is empty\n",
    "            p[1,1] = 3\n",
    "        for x, y in [[0,0],[0,2],[2,0],[2,2]]:  # the four corners\n",
    "            if p[x,y] == 1:\n",
    "                p[x,y] = 2\n",
    "    \n",
    "    policy = p / np.sum(p)\n",
    "    \n",
    "    return chooseMove(policy)\n",
    "\n",
    "def chooseMove(policy):\n",
    "    \n",
    "    u = np.random.uniform()\n",
    "    c = 0\n",
    "    \n",
    "    for x in [0, 1, 2]:\n",
    "        for y in [0, 1, 2]:\n",
    "            c += policy[x,y]\n",
    "            if u < c:\n",
    "                return x, y\n",
    "\n",
    "\n",
    "def policyMCMove(board, q, player):\n",
    "    key=board.toKey()\n",
    "    actions=board.possibleActions()\n",
    "    best=q[key,actions[0]]\n",
    "    bestAction=actions[0]\n",
    "    for a in actions[1:]:\n",
    "        if q[key,a]>best:\n",
    "            bestAction=a\n",
    "    x=bestAction % 3\n",
    "    y=int(bestAction/3)\n",
    "    return x,y\n",
    "\n",
    "def policyMCMoveEpsGreedy(board, q, player, epsilon):\n",
    "    if random.random()<epsilon:\n",
    "        a = random.choice(board.possibleActions())\n",
    "        x=a % 3\n",
    "        y=int(a/3)\n",
    "        return x,y\n",
    "    else:\n",
    "        return policyMCMove(board, q, player)\n",
    "\n",
    "def expectedTargetUnderEpsGreedy(board, q, epsilon):\n",
    "    e=0\n",
    "    actions = board.possibleActions()\n",
    "    key=board.toKey()\n",
    "    bestq=None\n",
    "    for a in actions:\n",
    "        e+=epsilon * q[(key,a)] / len(actions)\n",
    "        if bestq is None or q[(key,a)]>bestq:\n",
    "            bestq=q[(key,a)]\n",
    "    e+=bestq*(1-epsilon)\n",
    "    return e\n",
    "    \n",
    "def playGame(q,epsilon = -1):\n",
    "    nGames = 100000\n",
    "    win1 = 0\n",
    "    winM1 = 0\n",
    "    draw = 0\n",
    "    \n",
    "    for _ in tqdm(range(nGames)):\n",
    "        b = Board(np.zeros((3,3)))\n",
    "        player = random.choice([-1,1])\n",
    "        gameOver = 0\n",
    "        \n",
    "        while gameOver==0:\n",
    "            if player==1:\n",
    "                x,y=policyRandomMove(b)\n",
    "            else:\n",
    "                if epsilon > 0:\n",
    "                    x,y=policyMCMoveEpsGreedy(b,q,player,epsilon)\n",
    "                else:\n",
    "                    x,y=policyMCMove(b,q,player)                    \n",
    "            \n",
    "            gameOver = b.move(x,y,player)\n",
    "            \n",
    "            player = -player\n",
    "\n",
    "        if gameOver==2:\n",
    "            draw += 1\n",
    "        elif gameOver==1:\n",
    "            win1 += 1\n",
    "        else:\n",
    "            winM1 += 1\n",
    "\n",
    "\n",
    "    print(win1/nGames, winM1/nGames, draw/nGames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "startStates = getAllStartStates()\n",
    "\n",
    "q = {}\n",
    "n = {}\n",
    "\n",
    "for key in startStates:\n",
    "    board = Board(np.zeros((3,3)))\n",
    "    board.fromKey(key)\n",
    "              \n",
    "    for action in board.possibleActions():\n",
    "        q[(key, action)] = 0.5\n",
    "        n[(key, action)] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 55872/100000 [00:37<00:29, 1493.60it/s]"
     ]
    }
   ],
   "source": [
    "#epsilon greedy\n",
    "epsilon = 0.05\n",
    "nGames = 100000\n",
    "\n",
    "for _ in tqdm(range(nGames)):\n",
    "    b = Board(np.zeros((3,3)))\n",
    "    \n",
    "    player = random.choice([-1,1])\n",
    "    \n",
    "    gameOver = 0\n",
    "    \n",
    "    listStateAction = []\n",
    "    \n",
    "    while gameOver == 0:\n",
    "        if player == 1:\n",
    "            x,y = policyRandomMove(b)\n",
    "        else:\n",
    "            x,y = policyMCMoveEpsGreedy(b, q, player, epsilon)\n",
    "            listStateAction.append((b.toKey(), (x, y)))\n",
    "        \n",
    "        gameOver = b.move(x,y,player)\n",
    "        \n",
    "        player = -player\n",
    "        \n",
    "    r = 1\n",
    "    \n",
    "    if gameOver == 2:\n",
    "        r = 0.5\n",
    "    elif gameOver == 1:\n",
    "        r = 0\n",
    "\n",
    "    for k, (x,y) in listStateAction:\n",
    "        a = x + 3*y\n",
    "        \n",
    "        u = (k, a)\n",
    "        \n",
    "        q[u] = q[u] * n[u] + r\n",
    "        n[u] += 1\n",
    "        q[u] /= n[u]\n",
    "\n",
    "\n",
    "playGame(q, epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "startStates=getAllStartStates()\n",
    "\n",
    "q={}\n",
    "n={}\n",
    "\n",
    "for k in startStates:\n",
    "    b = Board(np.zeros((3,3)))\n",
    "    b.fromKey(k)\n",
    "    \n",
    "    for a in b.possibleActions():\n",
    "        q[(k,a)] = 0.5\n",
    "        n[(k,a)] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13186/100000 [00:11<01:13, 1178.79it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-83dfb2ee6270>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m                 \u001b[0mrandomAction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m                 \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpolicyMCMove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m             \u001b[0mlistStateAction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mgameOver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-48-cfaaf907361a>\u001b[0m in \u001b[0;36mpolicyMCMove\u001b[1;34m(board, q, player)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpolicyMCMove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mactions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpossibleActions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[0mbest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mbestAction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-47-52d79ff4e4a6>\u001b[0m in \u001b[0;36mpossibleActions\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misEmptyCell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m                     \u001b[0mactions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m3\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#exploring starts\n",
    "nGames = 100000\n",
    "for _ in tqdm(range(nGames)):\n",
    "    b = Board(np.zeros((3,3)))\n",
    "    player = -1\n",
    "    randomAction = True\n",
    "    gameOver = 0\n",
    "    listStateAction=[]\n",
    "    while gameOver==0:\n",
    "        if player==1:\n",
    "            x,y=policyRandomMove(b)\n",
    "        else:\n",
    "            key=b.toKey()\n",
    "            if randomAction:\n",
    "                p = np.where(b.b==0, 1, 0)\n",
    "                policy = p / np.sum(p)\n",
    "                x,y = chooseMove(policy)\n",
    "                randomAction=False\n",
    "            else:\n",
    "                x,y=policyMCMove(b,q,player)\n",
    "            listStateAction.append((key, (x, y)))\n",
    "        gameOver = b.move(x,y,player)\n",
    "        player=-player\n",
    "        \n",
    "    if gameOver==2:\n",
    "        r=0.5\n",
    "    elif gameOver==1:\n",
    "        r=0\n",
    "    else:\n",
    "        r=1\n",
    "    \n",
    "    for k, (x,y) in listStateAction[::]:\n",
    "        a=x+3*y\n",
    "        q[(k,a)]=q[(k,a)]*n[(k,a)]+r\n",
    "        n[(k,a)]+=1\n",
    "        q[(k,a)]/=n[(k,a)]\n",
    "\n",
    "playGame(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startStates=getAllStartStates()\n",
    "q={}\n",
    "c={}\n",
    "for k in startStates:\n",
    "    b = Board(np.zeros((3,3)))\n",
    "    b.fromKey(k)\n",
    "    for a in b.possibleActions():\n",
    "        q[(k,a)]=0.5\n",
    "        c[(k,a)]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#off policy\n",
    "nGames = 1000000\n",
    "for _ in tqdm(range(nGames)):\n",
    "    b = Board(np.zeros((3,3)))\n",
    "    player = random.choice([-1,1])\n",
    "    gameOver=0\n",
    "    listStateAction=[]\n",
    "    while gameOver==0:\n",
    "        if player==1:\n",
    "            x,y=policyRandomMove(b)\n",
    "        else:\n",
    "            x,y=policyRandomMove(b, True)\n",
    "            listStateAction.append((b.toKey(), (x, y)))\n",
    "        gameOver = b.move(x,y,player)\n",
    "        player=-player\n",
    "        \n",
    "    if gameOver==2:\n",
    "        r=0.5\n",
    "    elif gameOver==1:\n",
    "        r=0\n",
    "    else:\n",
    "        r=1\n",
    "\n",
    "    W=1\n",
    "    for k, (x,y) in listStateAction[::]:\n",
    "        a=x+3*y\n",
    "        c[(k,a)]=c[(k,a)]+W\n",
    "        q[(k,a)]=q[(k,a)]+W*(r-q[(k,a)])/c[(k,a)]\n",
    "        b = Board(np.zeros((3,3)))\n",
    "        b.fromKey(k)\n",
    "        pA=b.possibleActions()\n",
    "        bestA=pA[0]\n",
    "        for aa in pA[1:]:\n",
    "            if q[(k,aa)]>q[(k,bestA)]:\n",
    "                bestA=aa\n",
    "        if bestA!=a:\n",
    "            break\n",
    "        W=W*len(pA)\n",
    "\n",
    "playGame(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startStates=getAllStartStates()\n",
    "\n",
    "q={}\n",
    "\n",
    "for k in startStates:\n",
    "    b = Board(np.zeros((3,3)))\n",
    "    b.fromKey(k)\n",
    "    \n",
    "    for a in b.possibleActions():\n",
    "        q[(k,a)]=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sarsa\n",
    "nGames = 100000\n",
    "alpha=0.1\n",
    "epsilon = 0.1\n",
    "for _ in tqdm(range(nGames)):\n",
    "    b = Board(np.zeros((3,3)))\n",
    "    player = random.choice([-1,1])\n",
    "    gameOver=0\n",
    "    action=None\n",
    "    newAction=None\n",
    "    while gameOver==0:\n",
    "        if player==1:\n",
    "            x,y=policyRandomMove(b)\n",
    "        else:\n",
    "            x, y = policyMCMoveEpsGreedy(b,q,player,0.05)\n",
    "            if action is None:\n",
    "                action = x+3*y\n",
    "                key = b.toKey()\n",
    "            else:\n",
    "                newAction = x+3*y\n",
    "                newKey = b.toKey()\n",
    "        gameOver = b.move(x,y,player)\n",
    "        if gameOver==-1:\n",
    "            q[(key,action)]=q[(key,action)]+alpha*(1-q[(key,action)])\n",
    "        elif gameOver==1:\n",
    "            q[(key,action)]=q[(key,action)]+alpha*(0-q[(key,action)])\n",
    "        elif newAction is not None:\n",
    "            q[(key,action)]=q[(key,action)]+alpha*(q[(newKey,newAction)]-q[(key,action)])\n",
    "        if player==-1 and newAction is not None:\n",
    "            action=newAction\n",
    "            key=newKey\n",
    "        player=-player\n",
    "\n",
    "playGame(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startStates=getAllStartStates()\n",
    "q={}\n",
    "for k in startStates:\n",
    "    b = Board(np.zeros((3,3)))\n",
    "    b.fromKey(k)\n",
    "    for a in b.possibleActions():\n",
    "        q[(k,a)]=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#q learning\n",
    "nGames = 100000\n",
    "alpha=0.1\n",
    "for _ in tqdm(range(nGames)):\n",
    "    b = Board(np.zeros((3,3)))\n",
    "    player = random.choice([-1,1])\n",
    "    gameOver=0\n",
    "    action=None\n",
    "    newAction=None\n",
    "    while gameOver==0:\n",
    "        if player==1:\n",
    "            x,y=policyRandomMove(b)\n",
    "        else:\n",
    "            x, y = policyMCMoveEpsGreedy(b,q,player,0.1)\n",
    "            if action is None:\n",
    "                action = x+3*y\n",
    "                key = b.toKey()\n",
    "            else:\n",
    "                newAction = x+3*y\n",
    "                newKey = b.toKey()\n",
    "                pA=b.possibleActions()\n",
    "                maxq=q[(newKey,pA[0])]\n",
    "                for aa in pA[1:]:\n",
    "                    if q[(newKey,aa)]>maxq:\n",
    "                        maxq=q[(newKey,aa)]\n",
    "        gameOver = b.move(x,y,player)\n",
    "        if gameOver==-1:\n",
    "            q[(key,action)]=q[(key,action)]+alpha*(1-q[(key,action)])\n",
    "        elif gameOver==1:\n",
    "            q[(key,action)]=q[(key,action)]+alpha*(0-q[(key,action)])\n",
    "        elif newAction is not None:\n",
    "            q[(key,action)]=q[(key,action)]+alpha*(maxq-q[(key,action)])\n",
    "        if player==-1 and newAction is not None:\n",
    "            action=newAction\n",
    "            key=newKey\n",
    "        player=-player\n",
    "\n",
    "playGame(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startStates=getAllStartStates()\n",
    "q={}\n",
    "for k in startStates:\n",
    "    b = Board(np.zeros((3,3)))\n",
    "    b.fromKey(k)\n",
    "    for a in b.possibleActions():\n",
    "        q[(k,a)]=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expected sarsa where behaviour policy is eps greedy derived from q\n",
    "# (expected sarsa where behaviour policy is greedy derived from q = q learning)\n",
    "nGames = 100000\n",
    "alpha=0.1\n",
    "epsilon = 0.1\n",
    "for _ in tqdm(range(nGames)):\n",
    "    b = Board(np.zeros((3,3)))\n",
    "    \n",
    "    player = random.choice([-1,1])\n",
    "    \n",
    "    gameOver=0\n",
    "    \n",
    "    action = None\n",
    "    newAction = None\n",
    "    \n",
    "    while gameOver == 0:\n",
    "        if player == 1:\n",
    "            x,y=policyRandomMove(b)\n",
    "        else:\n",
    "            x, y = policyMCMoveEpsGreedy(b,q,player,epsilon)\n",
    "            if action is None:\n",
    "                action = x+3*y\n",
    "                key = b.toKey()\n",
    "            else:\n",
    "                newAction = x+3*y\n",
    "                newKey = b.toKey()\n",
    "                expectedTarget = expectedTargetUnderEpsGreedy(b, q, epsilon)\n",
    "        gameOver = b.move(x,y,player)\n",
    "        if gameOver==-1:\n",
    "            q[(key,action)]=q[(key,action)]+alpha*(1-q[(key,action)])\n",
    "        elif gameOver==1:\n",
    "            q[(key,action)]=q[(key,action)]+alpha*(0-q[(key,action)])\n",
    "        elif newAction is not None:\n",
    "            q[(key,action)]=q[(key,action)]+alpha*(expectedTarget-q[(key,action)])\n",
    "        if player==-1 and newAction is not None:\n",
    "            action=newAction\n",
    "            key=newKey\n",
    "        player=-player\n",
    "\n",
    "playGame(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
