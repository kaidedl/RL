{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm # loops show smart progress meter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class board:\n",
    "    def __init__(self, bInit):\n",
    "        self.b=bInit\n",
    "        \n",
    "    def check(self, player):\n",
    "        for i in range(3):\n",
    "            if self.b[i,0]==player and self.b[i,1]==player and self.b[i,2]==player:\n",
    "                return player\n",
    "            if self.b[0,i]==player and self.b[1,i]==player and self.b[2,i]==player:\n",
    "                return player\n",
    "        if self.b[0,0]==player and self.b[1,1]==player and self.b[2,2]==player:\n",
    "            return player\n",
    "        if self.b[0,2]==player and self.b[1,1]==player and self.b[2,0]==player:\n",
    "            return player\n",
    "        if np.sum(np.where(self.b==0,1,0))==0:\n",
    "            return 2\n",
    "        return 0\n",
    "\n",
    "    def toKey(self):\n",
    "        s=0\n",
    "        i=0\n",
    "        for x in range(3):\n",
    "            for y in range(3):\n",
    "                s+=(self.b[x,y]+2)*10**i\n",
    "                i+=1\n",
    "        return int(s)\n",
    "\n",
    "    def fromKey(self, i):\n",
    "        self.b=np.zeros((3,3))\n",
    "        for x in range(3):\n",
    "            for y in range(3):\n",
    "                self.b[x,y]=i%10 - 2\n",
    "                i=int(i/10)\n",
    "                \n",
    "    def move(self, x, y, player):\n",
    "        self.b[x,y]=player\n",
    "        return self.check(player)\n",
    "    \n",
    "    def possibleActions(self):\n",
    "        actions=[]\n",
    "        for x in range(3):\n",
    "            for y in range(3):\n",
    "                if self.b[x,y]==0:\n",
    "                    actions.append(x+3*y)\n",
    "        return actions\n",
    "    \n",
    "    \n",
    "def getAllStartStates():\n",
    "    def f(l, b, i):\n",
    "        x = i % 3\n",
    "        y = int(i / 3)\n",
    "        for p in [-1,0,1]:\n",
    "            b.b[x,y]=p\n",
    "            if np.sum(b.b==1)-np.sum(b.b==-1) in [0,1] and b.check(1)==0 and b.check(-1)==0:\n",
    "                l.append(b.toKey())\n",
    "            if i<8:\n",
    "                f(l, b, i+1)\n",
    "    \n",
    "    b=board(np.zeros((3,3)))\n",
    "    l = [b.toKey()]\n",
    "    f(l,b,0)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policyRandomMove(board, pure=False):\n",
    "    p = np.where(board.b==0, 1, 0)\n",
    "    if not pure:\n",
    "        if p[1,1]==1:\n",
    "            p[1,1]=3\n",
    "        for x,y in [[0,0],[0,2],[2,0],[2,2]]:\n",
    "            if p[x,y]==1:\n",
    "                p[x,y]=2\n",
    "    policy = p / np.sum(p)\n",
    "    return chooseMove(policy)\n",
    "\n",
    "def chooseMove(policy):\n",
    "    u = np.random.uniform()\n",
    "    c=0\n",
    "    for x in [0,1,2]:\n",
    "        for y in [0,1,2]:\n",
    "            c+=policy[x,y]\n",
    "            if u<c:\n",
    "                return x,y\n",
    "\n",
    "\n",
    "def policyMCMove(board, q, player):\n",
    "    key=board.toKey()\n",
    "    actions=board.possibleActions()\n",
    "    best=q[key,actions[0]]\n",
    "    bestAction=actions[0]\n",
    "    for a in actions[1:]:\n",
    "        if q[key,a]>best:\n",
    "            bestAction=a\n",
    "    x=bestAction % 3\n",
    "    y=int(bestAction/3)\n",
    "    return x,y\n",
    "\n",
    "def policyMCMoveEpsGreedy(board, q, player, epsilon):\n",
    "    if random.random()<epsilon:\n",
    "        a = random.choice(board.possibleActions())\n",
    "        x=a % 3\n",
    "        y=int(a/3)\n",
    "        return x,y\n",
    "    else:\n",
    "        return policyMCMove(board, q, player)\n",
    "\n",
    "def expectedTargetUnderEpsGreedy(board, q, epsilon):\n",
    "    e=0\n",
    "    actions = board.possibleActions()\n",
    "    key=board.toKey()\n",
    "    bestq=None\n",
    "    for a in actions:\n",
    "        e+=epsilon * q[(key,a)] / len(actions)\n",
    "        if bestq is None or q[(key,a)]>bestq:\n",
    "            bestq=q[(key,a)]\n",
    "    e+=bestq*(1-epsilon)\n",
    "    return e\n",
    "    \n",
    "def playGame(q,epsilon=-1):\n",
    "    nGames = 100000\n",
    "    win1 =0\n",
    "    winM1 = 0\n",
    "    draw=0\n",
    "    for _ in tqdm(range(nGames)):\n",
    "        b=board(np.zeros((3,3)))\n",
    "        player = random.choice([-1,1])\n",
    "        gameOver=0\n",
    "        while gameOver==0:\n",
    "            if player==1:\n",
    "                x,y=policyRandomMove(b)\n",
    "            else:\n",
    "                if epsilon>0:\n",
    "                    x,y=policyMCMoveEpsGreedy(b,q,player,epsilon)\n",
    "                else:\n",
    "                    x,y=policyMCMove(b,q,player)                    \n",
    "            gameOver = b.move(x,y,player)\n",
    "            player=-player\n",
    "\n",
    "        if gameOver==2:\n",
    "            draw+=1\n",
    "        elif gameOver==1:\n",
    "            win1+=1\n",
    "        else:\n",
    "            winM1+=1\n",
    "\n",
    "\n",
    "    print(win1/nGames, winM1/nGames, draw/nGames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "startStates=getAllStartStates()\n",
    "q={}\n",
    "c={}\n",
    "n={}\n",
    "for k in startStates:\n",
    "    b=board(np.zeros((3,3)))\n",
    "    b.fromKey(k)\n",
    "    for a in b.possibleActions():\n",
    "        q[(k,a)]=0.5\n",
    "        n[(k,a)]=0\n",
    "        c[(k,a)]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:29<00:00, 3413.68it/s]\n",
      "100%|██████████| 100000/100000 [00:24<00:00, 4120.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12792 0.81195 0.06013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#epsilon greedy\n",
    "epsilon=0.05\n",
    "nGames = 100000\n",
    "for _ in tqdm(range(nGames)):\n",
    "    b=board(np.zeros((3,3)))\n",
    "    player = random.choice([-1,1])\n",
    "    gameOver=0\n",
    "    listStateAction=[]\n",
    "    while gameOver==0:\n",
    "        if player==1:\n",
    "            x,y=policyRandomMove(b)\n",
    "        else:\n",
    "            x,y=policyMCMoveEpsGreedy(b,q,player,epsilon)\n",
    "            listStateAction.append((b.toKey(), (x, y)))\n",
    "        gameOver = b.move(x,y,player)\n",
    "        player=-player\n",
    "        \n",
    "    if gameOver==2:\n",
    "        r=0.5\n",
    "    elif gameOver==1:\n",
    "        r=0\n",
    "    else:\n",
    "        r=1\n",
    "    \n",
    "    for k, (x,y) in listStateAction[::]:\n",
    "        a=x+3*y\n",
    "        q[(k,a)]=q[(k,a)]*n[(k,a)]+r\n",
    "        n[(k,a)]+=1\n",
    "        q[(k,a)]/=n[(k,a)]\n",
    "\n",
    "\n",
    "playGame(q,epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "startStates=getAllStartStates()\n",
    "q={}\n",
    "c={}\n",
    "n={}\n",
    "for k in startStates:\n",
    "    b=board(np.zeros((3,3)))\n",
    "    b.fromKey(k)\n",
    "    for a in b.possibleActions():\n",
    "        q[(k,a)]=0.5\n",
    "        n[(k,a)]=0\n",
    "        c[(k,a)]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:32<00:00, 3121.77it/s]\n",
      "100%|██████████| 100000/100000 [00:27<00:00, 3697.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04568 0.8127 0.14162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#exploring starts\n",
    "nGames = 100000\n",
    "for _ in tqdm(range(nGames)):\n",
    "    b=board(np.zeros((3,3)))\n",
    "    player = -1\n",
    "    randomAction=True\n",
    "    gameOver=0\n",
    "    listStateAction=[]\n",
    "    while gameOver==0:\n",
    "        if player==1:\n",
    "            x,y=policyRandomMove(b)\n",
    "        else:\n",
    "            key=b.toKey()\n",
    "            if randomAction:\n",
    "                p = np.where(b.b==0, 1, 0)\n",
    "                policy = p / np.sum(p)\n",
    "                x,y = chooseMove(policy)\n",
    "                randomAction=False\n",
    "            else:\n",
    "                x,y=policyMCMove(b,q,player)\n",
    "            listStateAction.append((key, (x, y)))\n",
    "        gameOver = b.move(x,y,player)\n",
    "        player=-player\n",
    "        \n",
    "    if gameOver==2:\n",
    "        r=0.5\n",
    "    elif gameOver==1:\n",
    "        r=0\n",
    "    else:\n",
    "        r=1\n",
    "    \n",
    "    for k, (x,y) in listStateAction[::]:\n",
    "        a=x+3*y\n",
    "        q[(k,a)]=q[(k,a)]*n[(k,a)]+r\n",
    "        n[(k,a)]+=1\n",
    "        q[(k,a)]/=n[(k,a)]\n",
    "\n",
    "playGame(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "startStates=getAllStartStates()\n",
    "q={}\n",
    "c={}\n",
    "for k in startStates:\n",
    "    b=board(np.zeros((3,3)))\n",
    "    b.fromKey(k)\n",
    "    for a in b.possibleActions():\n",
    "        q[(k,a)]=0.5\n",
    "        c[(k,a)]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [06:25<00:00, 2592.33it/s]\n",
      "100%|██████████| 100000/100000 [00:28<00:00, 3551.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21706 0.70505 0.07789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#off policy\n",
    "nGames = 1000000\n",
    "for _ in tqdm(range(nGames)):\n",
    "    b=board(np.zeros((3,3)))\n",
    "    player = random.choice([-1,1])\n",
    "    gameOver=0\n",
    "    listStateAction=[]\n",
    "    while gameOver==0:\n",
    "        if player==1:\n",
    "            x,y=policyRandomMove(b)\n",
    "        else:\n",
    "            x,y=policyRandomMove(b, True)\n",
    "            listStateAction.append((b.toKey(), (x, y)))\n",
    "        gameOver = b.move(x,y,player)\n",
    "        player=-player\n",
    "        \n",
    "    if gameOver==2:\n",
    "        r=0.5\n",
    "    elif gameOver==1:\n",
    "        r=0\n",
    "    else:\n",
    "        r=1\n",
    "\n",
    "    W=1\n",
    "    for k, (x,y) in listStateAction[::]:\n",
    "        a=x+3*y\n",
    "        c[(k,a)]=c[(k,a)]+W\n",
    "        q[(k,a)]=q[(k,a)]+W*(r-q[(k,a)])/c[(k,a)]\n",
    "        b=board(np.zeros((3,3)))\n",
    "        b.fromKey(k)\n",
    "        pA=b.possibleActions()\n",
    "        bestA=pA[0]\n",
    "        for aa in pA[1:]:\n",
    "            if q[(k,aa)]>q[(k,bestA)]:\n",
    "                bestA=aa\n",
    "        if bestA!=a:\n",
    "            break\n",
    "        W=W*len(pA)\n",
    "\n",
    "playGame(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "startStates=getAllStartStates()\n",
    "q={}\n",
    "for k in startStates:\n",
    "    b=board(np.zeros((3,3)))\n",
    "    b.fromKey(k)\n",
    "    for a in b.possibleActions():\n",
    "        q[(k,a)]=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:34<00:00, 2877.45it/s]\n",
      "100%|██████████| 100000/100000 [00:29<00:00, 3440.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08212 0.69233 0.22555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#sarsa\n",
    "nGames = 100000\n",
    "alpha=0.1\n",
    "epsilon = 0.1\n",
    "for _ in tqdm(range(nGames)):\n",
    "    b=board(np.zeros((3,3)))\n",
    "    player = random.choice([-1,1])\n",
    "    gameOver=0\n",
    "    action=None\n",
    "    newAction=None\n",
    "    while gameOver==0:\n",
    "        if player==1:\n",
    "            x,y=policyRandomMove(b)\n",
    "        else:\n",
    "            x, y = policyMCMoveEpsGreedy(b,q,player,0.05)\n",
    "            if action is None:\n",
    "                action = x+3*y\n",
    "                key = b.toKey()\n",
    "            else:\n",
    "                newAction = x+3*y\n",
    "                newKey = b.toKey()\n",
    "        gameOver = b.move(x,y,player)\n",
    "        if gameOver==-1:\n",
    "            q[(key,action)]=q[(key,action)]+alpha*(1-q[(key,action)])\n",
    "        elif gameOver==1:\n",
    "            q[(key,action)]=q[(key,action)]+alpha*(0-q[(key,action)])\n",
    "        elif newAction is not None:\n",
    "            q[(key,action)]=q[(key,action)]+alpha*(q[(newKey,newAction)]-q[(key,action)])\n",
    "        if player==-1 and newAction is not None:\n",
    "            action=newAction\n",
    "            key=newKey\n",
    "        player=-player\n",
    "\n",
    "playGame(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "startStates=getAllStartStates()\n",
    "q={}\n",
    "for k in startStates:\n",
    "    b=board(np.zeros((3,3)))\n",
    "    b.fromKey(k)\n",
    "    for a in b.possibleActions():\n",
    "        q[(k,a)]=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:40<00:00, 2444.97it/s]\n",
      "100%|██████████| 100000/100000 [00:32<00:00, 3036.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08508 0.71081 0.20411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#q learning\n",
    "nGames = 100000\n",
    "alpha=0.1\n",
    "for _ in tqdm(range(nGames)):\n",
    "    b=board(np.zeros((3,3)))\n",
    "    player = random.choice([-1,1])\n",
    "    gameOver=0\n",
    "    action=None\n",
    "    newAction=None\n",
    "    while gameOver==0:\n",
    "        if player==1:\n",
    "            x,y=policyRandomMove(b)\n",
    "        else:\n",
    "            x, y = policyMCMoveEpsGreedy(b,q,player,0.1)\n",
    "            if action is None:\n",
    "                action = x+3*y\n",
    "                key = b.toKey()\n",
    "            else:\n",
    "                newAction = x+3*y\n",
    "                newKey = b.toKey()\n",
    "                pA=b.possibleActions()\n",
    "                maxq=q[(newKey,pA[0])]\n",
    "                for aa in pA[1:]:\n",
    "                    if q[(newKey,aa)]>maxq:\n",
    "                        maxq=q[(newKey,aa)]\n",
    "        gameOver = b.move(x,y,player)\n",
    "        if gameOver==-1:\n",
    "            q[(key,action)]=q[(key,action)]+alpha*(1-q[(key,action)])\n",
    "        elif gameOver==1:\n",
    "            q[(key,action)]=q[(key,action)]+alpha*(0-q[(key,action)])\n",
    "        elif newAction is not None:\n",
    "            q[(key,action)]=q[(key,action)]+alpha*(maxq-q[(key,action)])\n",
    "        if player==-1 and newAction is not None:\n",
    "            action=newAction\n",
    "            key=newKey\n",
    "        player=-player\n",
    "\n",
    "playGame(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "startStates=getAllStartStates()\n",
    "q={}\n",
    "for k in startStates:\n",
    "    b=board(np.zeros((3,3)))\n",
    "    b.fromKey(k)\n",
    "    for a in b.possibleActions():\n",
    "        q[(k,a)]=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:38<00:00, 2567.36it/s]\n",
      "100%|██████████| 100000/100000 [00:28<00:00, 3450.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08438 0.72575 0.18987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# expected sarsa where behaviour policy is eps greedy derived from q\n",
    "# (expected sarsa where behaviour policy is greedy derived from q = q learning)\n",
    "nGames = 100000\n",
    "alpha=0.1\n",
    "epsilon = 0.1\n",
    "for _ in tqdm(range(nGames)):\n",
    "    b=board(np.zeros((3,3)))\n",
    "    player = random.choice([-1,1])\n",
    "    gameOver=0\n",
    "    action=None\n",
    "    newAction=None\n",
    "    while gameOver==0:\n",
    "        if player==1:\n",
    "            x,y=policyRandomMove(b)\n",
    "        else:\n",
    "            x, y = policyMCMoveEpsGreedy(b,q,player,epsilon)\n",
    "            if action is None:\n",
    "                action = x+3*y\n",
    "                key = b.toKey()\n",
    "            else:\n",
    "                newAction = x+3*y\n",
    "                newKey = b.toKey()\n",
    "                expectedTarget = expectedTargetUnderEpsGreedy(b, q, epsilon)\n",
    "        gameOver = b.move(x,y,player)\n",
    "        if gameOver==-1:\n",
    "            q[(key,action)]=q[(key,action)]+alpha*(1-q[(key,action)])\n",
    "        elif gameOver==1:\n",
    "            q[(key,action)]=q[(key,action)]+alpha*(0-q[(key,action)])\n",
    "        elif newAction is not None:\n",
    "            q[(key,action)]=q[(key,action)]+alpha*(expectedTarget-q[(key,action)])\n",
    "        if player==-1 and newAction is not None:\n",
    "            action=newAction\n",
    "            key=newKey\n",
    "        player=-player\n",
    "\n",
    "playGame(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
